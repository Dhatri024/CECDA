paper_id,claim_sentence,csv_score,modality,comparative,generality,scope,ebv_score,cds_score
0073cc73e1873b35345209b50a3dab66-Paper-Conference,"extensive experiments have demonstrated the effectiveness of our method for large-scale scene novel view synthesis, which outperforms relevant state-of-the-art baselines.",0.61,0.5,1.0,0.4,0.4,0.32,0.29
001608167bb652337af5df0129aeaabd-Paper-Conference,"we present a new algorithm, cross-episodic curriculum (cec), to boost the learn- ing efficiency and generalization of transformer agents.",0.52,0.5,0.3,1.0,0.4,0.34,0.18
007f4927e60699392425f267d43f0940-Paper-Conference,we propose a robust natural actor-critic (rnac) approach that incorporates the new uncertainty sets and employs function approximation.,0.4,0.5,0.3,0.4,0.4,0.2,0.2
0001ca33ba34ce0351e4612b744b3936-Paper-Conference,"we propose the sparse additive mechanism shift variational autoencoder, sams-vae, to combine compositionality, disentanglement, and interpretability for perturbation models.",0.44,0.5,0.3,0.4,0.6,0.17,0.27
0001ca33ba34ce0351e4612b744b3936-Paper-Conference,"sams-vae outperforms comparable models in terms of generalization across in-distribution and out-of-distribution tasks, including a combinatorial reasoning task under re- source paucity, and yields interpretable latent structures which correlate strongly to known biological mechanisms.",0.77,0.5,1.0,1.0,0.6,0.17,0.6
0001ca33ba34ce0351e4612b744b3936-Paper-Conference,our results suggest sams-vae is an interesting addition to the modeling toolkit for machine learning-driven scientiÔ¨Åc discovery.,0.31,0.2,0.3,0.4,0.4,0.17,0.13999999999999999
0001ca33ba34ce0351e4612b744b3936-Paper-Conference,"we also introduce cpa-vae, which ablates the sparsity mechanism we propose, yielding a generative model with similar assumptions as the popula",0.44,0.5,0.3,0.4,0.6,0.17,0.27
002262941c9edfd472a79298b2ac5e17-Paper-Conference,we present a novel methodology aimed at optimizing the application of frozen large language models (llms) for resource-intensive vision-language (vl) pre-training.,0.4,0.5,0.3,0.4,0.4,0.31,0.09000000000000002
002262941c9edfd472a79298b2ac5e17-Paper-Conference,"we introduce the prompt-transformer (p-former), a model that predicts these ideal prompts, which is trained exclusively on linguistic data, bypassing the need for image-text pairings.",0.4,0.5,0.3,0.4,0.4,0.31,0.09000000000000002
0021c2cb1b9b6a71ac478ea52a93b25a-Paper-Conference,"we propose an adversarial masked contrastive paint- ing (amcp) process, which creates a contrast between the original image and a painted image in which a masked area is painted using off-the-shelf generative models.",0.4,0.5,0.3,0.4,0.4,0.41,-0.009999999999999953
0021c2cb1b9b6a71ac478ea52a93b25a-Paper-Conference,"our ex- perimental results demonstrate that paintseg outperforms existing approaches in coarse mask-prompt, box-prompt, and point-prompt segmentation tasks, pro- viding a training-free solution suitable for unsupervised segmentation.",0.61,0.5,1.0,0.4,0.4,0.41,0.2
